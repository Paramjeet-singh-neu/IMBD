{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d34c2df2-5187-48fc-80c4-b2e89f70abb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# IMDB DLT Pipeline - Silver to Snowflake Gold Layer\n",
    "# =========================================================================\n",
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# =========================================================================\n",
    "# SNOWFLAKE CONNECTION CONFIGURATION\n",
    "# =========================================================================\n",
    "\n",
    "SNOWFLAKE_OPTIONS = {\n",
    "    \"sfUrl\": \"RCVOYBU-ZSC95331.snowflakecomputing.com\",\n",
    "    \"sfUser\": \"IMDB_USER\",\n",
    "    \"sfPassword\": \"IMDB\",\n",
    "    \"sfDatabase\": \"IMDB_DB\",\n",
    "    \"sfSchema\": \"DW\",\n",
    "    \"sfWarehouse\": \"IMDB_WH\",\n",
    "    \"sfRole\": \"IMDB_ROLE\"\n",
    "}\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_TITLE_BASICS\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_title_basics\",\n",
    "    comment=\"Title basics dimension table in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_title_basics():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    \n",
    "    title_df = (\n",
    "        silver_df\n",
    "        .select(\n",
    "            \"TCONST\",\n",
    "            \"TITLE_TYPE\",\n",
    "            \"PRIMARY_TITLE\",\n",
    "            \"ORIGINAL_TITLE\",\n",
    "            \"IS_ADULT\",\n",
    "            \"START_YEAR\",\n",
    "            \"END_YEAR\"\n",
    "        )\n",
    "        .filter(col(\"TCONST\").isNotNull())\n",
    "        .dropDuplicates([\"TCONST\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"TCONST\")\n",
    "    title_df = title_df.withColumn(\"TITLE_BASICS_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = title_df.select(\n",
    "        col(\"TITLE_BASICS_SK\").cast(\"int\"),\n",
    "        col(\"TCONST\").alias(\"TITLE_BASICS_TCONST\"),\n",
    "        col(\"TITLE_TYPE\"),\n",
    "        col(\"PRIMARY_TITLE\"),\n",
    "        col(\"ORIGINAL_TITLE\"),\n",
    "        col(\"IS_ADULT\").cast(\"int\"),\n",
    "        col(\"START_YEAR\").cast(\"int\"),\n",
    "        col(\"END_YEAR\").cast(\"int\"),\n",
    "        lit(\"PARAM\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_TITLE_BASICS\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_GENRE\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_genre\",\n",
    "    comment=\"Genre dimension table in Snowflake - exploded from title_basics\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_genre():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    \n",
    "    genre_df = (\n",
    "        silver_df\n",
    "        .select(explode(split(col(\"GENRES\"), \",\")).alias(\"GENRE_NAME\"))\n",
    "        .withColumn(\"GENRE_NAME\", trim(col(\"GENRE_NAME\")))\n",
    "        .filter(col(\"GENRE_NAME\").isNotNull() & (col(\"GENRE_NAME\") != \"\") & (col(\"GENRE_NAME\") != \"unknown\"))\n",
    "        .dropDuplicates([\"GENRE_NAME\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"GENRE_NAME\")\n",
    "    genre_df = genre_df.withColumn(\"GENRE_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = genre_df.select(\n",
    "        col(\"GENRE_SK\").cast(\"int\"),\n",
    "        col(\"GENRE_NAME\"),\n",
    "        lit(\"PARAM\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DT\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_GENRE\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_PERSON\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_person\",\n",
    "    comment=\"Person dimension table in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_person():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_name_basics\")\n",
    "    \n",
    "    person_df = (\n",
    "        silver_df\n",
    "        .select(\n",
    "            \"NCONST\",\n",
    "            \"PRIMARY_NAME\",\n",
    "            \"BIRTH_YEAR\",\n",
    "            \"DEATH_YEAR\",\n",
    "            \"IS_ALIVE\"\n",
    "        )\n",
    "        .filter(col(\"NCONST\").isNotNull())\n",
    "        .dropDuplicates([\"NCONST\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"NCONST\")\n",
    "    person_df = person_df.withColumn(\"PERSON_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = person_df.select(\n",
    "        col(\"PERSON_SK\").cast(\"int\"),\n",
    "        col(\"NCONST\"),\n",
    "        col(\"PRIMARY_NAME\"),\n",
    "        col(\"BIRTH_YEAR\").cast(\"int\"),\n",
    "        col(\"DEATH_YEAR\").cast(\"int\"),\n",
    "        when(col(\"IS_ALIVE\") == True, 1).otherwise(0).cast(\"int\").alias(\"IS_ALIVE\"),\n",
    "        lit(\"PRATHUSH\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_PERSON\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_PROFESSION\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_profession\",\n",
    "    comment=\"Profession dimension table in Snowflake - exploded from name_basics\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_profession():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_name_basics\")\n",
    "    \n",
    "    profession_df = (\n",
    "        silver_df\n",
    "        .select(explode(split(col(\"PRIMARY_PROFESSION\"), \",\")).alias(\"PROFESSION_NAME\"))\n",
    "        .withColumn(\"PROFESSION_NAME\", trim(col(\"PROFESSION_NAME\")))\n",
    "        .filter(col(\"PROFESSION_NAME\").isNotNull() & (col(\"PROFESSION_NAME\") != \"\") & (col(\"PROFESSION_NAME\") != \"Unknown\"))\n",
    "        .dropDuplicates([\"PROFESSION_NAME\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"PROFESSION_NAME\")\n",
    "    profession_df = profession_df.withColumn(\"PROFESSION_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = profession_df.select(\n",
    "        col(\"PROFESSION_SK\").cast(\"int\"),\n",
    "        col(\"PROFESSION_NAME\"),\n",
    "        lit(\"NIKHIL\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_PROFESSION\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_JOB\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_job\",\n",
    "    comment=\"Job category dimension table in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_job():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_title_principals\")\n",
    "    \n",
    "    job_df = (\n",
    "        silver_df\n",
    "        .select(col(\"CATEGORY\").alias(\"JOB_CATEGORY\"))\n",
    "        .filter(col(\"JOB_CATEGORY\").isNotNull() & (col(\"JOB_CATEGORY\") != \"unknown\"))\n",
    "        .dropDuplicates([\"JOB_CATEGORY\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"JOB_CATEGORY\")\n",
    "    job_df = job_df.withColumn(\"JOB_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = job_df.select(\n",
    "        col(\"JOB_SK\").cast(\"int\"),\n",
    "        col(\"JOB_CATEGORY\"),\n",
    "        lit(\"PRATHUSH\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_JOB\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_REGION (with Unknown row for -1 SK)\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_region\",\n",
    "    comment=\"Region dimension table in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_region():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_title_region\")\n",
    "    \n",
    "    region_df = (\n",
    "        silver_df\n",
    "        .select(\"REGION_CODE\", \"REGION_NAME\")\n",
    "        .filter(col(\"REGION_CODE\").isNotNull())\n",
    "        .dropDuplicates([\"REGION_CODE\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"REGION_CODE\")\n",
    "    region_df = region_df.withColumn(\"REGION_SK\", row_number().over(w))\n",
    "    \n",
    "    # Create Unknown row for missing/null regions (SK = -1)\n",
    "    unknown_row = spark.createDataFrame(\n",
    "        [(-1, \"UNK\", \"Unknown\")], \n",
    "        [\"REGION_SK\", \"REGION_CODE\", \"REGION_NAME\"]\n",
    "    )\n",
    "    \n",
    "    # Union with existing data\n",
    "    region_df = region_df.select(\"REGION_SK\", \"REGION_CODE\", \"REGION_NAME\").union(unknown_row)\n",
    "    \n",
    "    final_df = region_df.select(\n",
    "        col(\"REGION_SK\").cast(\"int\"),\n",
    "        col(\"REGION_CODE\"),\n",
    "        col(\"REGION_NAME\"),\n",
    "        lit(\"PARAM\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DT\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_REGION\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_LANGUAGE (with Unknown row for -1 SK)\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_language\",\n",
    "    comment=\"Language dimension table in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_language():\n",
    "    silver_df = spark.read.table(\"imdb_final_project.silver.silver_title_language_codes\")\n",
    "    \n",
    "    language_df = (\n",
    "        silver_df\n",
    "        .select(\"LANGUAGE_CODE\", \"LANGUAGE_NAME\")\n",
    "        .filter(col(\"LANGUAGE_CODE\").isNotNull())\n",
    "        .dropDuplicates([\"LANGUAGE_CODE\"])\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"LANGUAGE_CODE\")\n",
    "    language_df = language_df.withColumn(\"LANGUAGE_SK\", row_number().over(w))\n",
    "    \n",
    "    # Create Unknown row for missing/null languages (SK = -1)\n",
    "    unknown_row = spark.createDataFrame(\n",
    "        [(-1, \"UNK\", \"Unknown\")], \n",
    "        [\"LANGUAGE_SK\", \"LANGUAGE_CODE\", \"LANGUAGE_NAME\"]\n",
    "    )\n",
    "    \n",
    "    # Union with existing data\n",
    "    language_df = language_df.select(\"LANGUAGE_SK\", \"LANGUAGE_CODE\", \"LANGUAGE_NAME\").union(unknown_row)\n",
    "    \n",
    "    final_df = language_df.select(\n",
    "        col(\"LANGUAGE_SK\").cast(\"int\"),\n",
    "        col(\"LANGUAGE_CODE\"),\n",
    "        col(\"LANGUAGE_NAME\"),\n",
    "        lit(\"PRATHUSH\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_LANGUAGE\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# DIM_TITLE_AKAS (with coalesce for null FKs to -1)\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_dim_title_akas\",\n",
    "    comment=\"Title AKAS dimension table in Snowflake with FK lookups\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"dimension\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def dim_title_akas():\n",
    "    silver_akas = spark.read.table(\"imdb_final_project.silver.silver_title_akas\")\n",
    "    silver_basics = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    silver_region = spark.read.table(\"imdb_final_project.silver.silver_title_region\")\n",
    "    silver_language = spark.read.table(\"imdb_final_project.silver.silver_title_language_codes\")\n",
    "    \n",
    "    # Title lookup\n",
    "    title_df = (\n",
    "        silver_basics\n",
    "        .select(\"TCONST\")\n",
    "        .filter(col(\"TCONST\").isNotNull())\n",
    "        .dropDuplicates([\"TCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"TCONST\")\n",
    "    title_df = title_df.withColumn(\"TITLE_BASICS_SK\", row_number().over(w))\n",
    "    \n",
    "    # Region lookup\n",
    "    region_df = (\n",
    "        silver_region\n",
    "        .select(\"REGION_CODE\")\n",
    "        .filter(col(\"REGION_CODE\").isNotNull())\n",
    "        .dropDuplicates([\"REGION_CODE\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"REGION_CODE\")\n",
    "    region_df = region_df.withColumn(\"REGION_SK\", row_number().over(w))\n",
    "    \n",
    "    # Language lookup\n",
    "    language_df = (\n",
    "        silver_language\n",
    "        .select(\"LANGUAGE_CODE\")\n",
    "        .filter(col(\"LANGUAGE_CODE\").isNotNull())\n",
    "        .dropDuplicates([\"LANGUAGE_CODE\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"LANGUAGE_CODE\")\n",
    "    language_df = language_df.withColumn(\"LANGUAGE_SK\", row_number().over(w))\n",
    "    \n",
    "    # Join AKAS with lookups\n",
    "    akas_df = (\n",
    "        silver_akas\n",
    "        .join(title_df, silver_akas[\"TITLE_ID\"] == title_df[\"TCONST\"], \"left\")\n",
    "        .join(region_df, silver_akas[\"REGION\"] == region_df[\"REGION_CODE\"], \"left\")\n",
    "        .join(language_df, silver_akas[\"LANGUAGE\"] == language_df[\"LANGUAGE_CODE\"], \"left\")\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(\"TITLE_ID\", \"ORDERING\")\n",
    "    akas_df = akas_df.withColumn(\"TITLE_AKA_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = akas_df.select(\n",
    "        col(\"TITLE_AKA_SK\").cast(\"int\"),\n",
    "        col(\"TITLE_BASICS_SK\").cast(\"int\"),\n",
    "        col(\"TYPES\").alias(\"TITLE_AKAS_TYPES\"),\n",
    "        col(\"IS_ORIGINAL_TITLE\").cast(\"int\"),\n",
    "        coalesce(col(\"REGION_SK\"), lit(-1)).cast(\"int\").alias(\"REGION_SK\"),\n",
    "        coalesce(col(\"LANGUAGE_SK\"), lit(-1)).cast(\"int\").alias(\"LANGUAGE_SK\"),\n",
    "        lit(\"NIKHIL\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"DIM_TITLE_AKAS\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# BRIDGE_TITLE_GENRE\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_bridge_title_genre\",\n",
    "    comment=\"Bridge table linking titles to genres in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"bridge\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def bridge_title_genre():\n",
    "    silver_basics = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    \n",
    "    title_df = (\n",
    "        silver_basics\n",
    "        .select(\"TCONST\")\n",
    "        .filter(col(\"TCONST\").isNotNull())\n",
    "        .dropDuplicates([\"TCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"TCONST\")\n",
    "    title_df = title_df.withColumn(\"TITLE_BASICS_SK\", row_number().over(w))\n",
    "    \n",
    "    genre_df = (\n",
    "        silver_basics\n",
    "        .select(explode(split(col(\"GENRES\"), \",\")).alias(\"GENRE_NAME\"))\n",
    "        .withColumn(\"GENRE_NAME\", trim(col(\"GENRE_NAME\")))\n",
    "        .filter(col(\"GENRE_NAME\").isNotNull() & (col(\"GENRE_NAME\") != \"\") & (col(\"GENRE_NAME\") != \"unknown\"))\n",
    "        .dropDuplicates([\"GENRE_NAME\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"GENRE_NAME\")\n",
    "    genre_df = genre_df.withColumn(\"GENRE_SK\", row_number().over(w))\n",
    "    \n",
    "    exploded_df = (\n",
    "        silver_basics\n",
    "        .select(\n",
    "            col(\"TCONST\"),\n",
    "            explode(split(col(\"GENRES\"), \",\")).alias(\"GENRE_NAME\")\n",
    "        )\n",
    "        .withColumn(\"GENRE_NAME\", trim(col(\"GENRE_NAME\")))\n",
    "        .filter(col(\"GENRE_NAME\").isNotNull() & (col(\"GENRE_NAME\") != \"\") & (col(\"GENRE_NAME\") != \"unknown\"))\n",
    "    )\n",
    "    \n",
    "    bridge_df = (\n",
    "        exploded_df\n",
    "        .join(title_df, exploded_df[\"TCONST\"] == title_df[\"TCONST\"], \"inner\")\n",
    "        .join(genre_df, exploded_df[\"GENRE_NAME\"] == genre_df[\"GENRE_NAME\"], \"inner\")\n",
    "        .select(\n",
    "            title_df[\"TITLE_BASICS_SK\"],\n",
    "            genre_df[\"GENRE_SK\"]\n",
    "        )\n",
    "        .dropDuplicates([\"TITLE_BASICS_SK\", \"GENRE_SK\"])\n",
    "    )\n",
    "    \n",
    "    final_df = bridge_df.select(\n",
    "        col(\"TITLE_BASICS_SK\").cast(\"int\"),\n",
    "        col(\"GENRE_SK\").cast(\"int\"),\n",
    "        lit(\"PARAM\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"BRIDGE_TITLE_GENRE\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# BRIDGE_PERSON_PROFESSION\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_bridge_person_profession\",\n",
    "    comment=\"Bridge table linking persons to professions in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"bridge\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def bridge_person_profession():\n",
    "    silver_names = spark.read.table(\"imdb_final_project.silver.silver_name_basics\")\n",
    "    \n",
    "    person_df = (\n",
    "        silver_names\n",
    "        .select(\"NCONST\")\n",
    "        .filter(col(\"NCONST\").isNotNull())\n",
    "        .dropDuplicates([\"NCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"NCONST\")\n",
    "    person_df = person_df.withColumn(\"PERSON_SK\", row_number().over(w))\n",
    "    \n",
    "    profession_df = (\n",
    "        silver_names\n",
    "        .select(explode(split(col(\"PRIMARY_PROFESSION\"), \",\")).alias(\"PROFESSION_NAME\"))\n",
    "        .withColumn(\"PROFESSION_NAME\", trim(col(\"PROFESSION_NAME\")))\n",
    "        .filter(col(\"PROFESSION_NAME\").isNotNull() & (col(\"PROFESSION_NAME\") != \"\") & (col(\"PROFESSION_NAME\") != \"Unknown\"))\n",
    "        .dropDuplicates([\"PROFESSION_NAME\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"PROFESSION_NAME\")\n",
    "    profession_df = profession_df.withColumn(\"PROFESSION_SK\", row_number().over(w))\n",
    "    \n",
    "    exploded_df = (\n",
    "        silver_names\n",
    "        .select(\n",
    "            col(\"NCONST\"),\n",
    "            explode(split(col(\"PRIMARY_PROFESSION\"), \",\")).alias(\"PROFESSION_NAME\")\n",
    "        )\n",
    "        .withColumn(\"PROFESSION_NAME\", trim(col(\"PROFESSION_NAME\")))\n",
    "        .filter(col(\"PROFESSION_NAME\").isNotNull() & (col(\"PROFESSION_NAME\") != \"\") & (col(\"PROFESSION_NAME\") != \"Unknown\"))\n",
    "    )\n",
    "    \n",
    "    bridge_df = (\n",
    "        exploded_df\n",
    "        .join(person_df, exploded_df[\"NCONST\"] == person_df[\"NCONST\"], \"inner\")\n",
    "        .join(profession_df, exploded_df[\"PROFESSION_NAME\"] == profession_df[\"PROFESSION_NAME\"], \"inner\")\n",
    "        .select(\n",
    "            person_df[\"PERSON_SK\"],\n",
    "            profession_df[\"PROFESSION_SK\"]\n",
    "        )\n",
    "        .dropDuplicates([\"PERSON_SK\", \"PROFESSION_SK\"])\n",
    "    )\n",
    "    \n",
    "    final_df = bridge_df.select(\n",
    "        col(\"PERSON_SK\").cast(\"int\"),\n",
    "        col(\"PROFESSION_SK\").cast(\"int\"),\n",
    "        lit(\"NIKHIL\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"BRIDGE_PERSON_PROFESSION\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# FACT_TITLE_PARTICIPATION\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_fact_title_participation\",\n",
    "    comment=\"Fact table for title participation in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"fact\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def fact_title_participation():\n",
    "    silver_principals = spark.read.table(\"imdb_final_project.silver.silver_title_principals\")\n",
    "    silver_basics = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    silver_names = spark.read.table(\"imdb_final_project.silver.silver_name_basics\")\n",
    "    \n",
    "    title_df = (\n",
    "        silver_basics\n",
    "        .select(\"TCONST\")\n",
    "        .filter(col(\"TCONST\").isNotNull())\n",
    "        .dropDuplicates([\"TCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"TCONST\")\n",
    "    title_df = title_df.withColumn(\"TITLE_BASICS_SK\", row_number().over(w))\n",
    "    \n",
    "    person_df = (\n",
    "        silver_names\n",
    "        .select(\"NCONST\")\n",
    "        .filter(col(\"NCONST\").isNotNull())\n",
    "        .dropDuplicates([\"NCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"NCONST\")\n",
    "    person_df = person_df.withColumn(\"PERSON_SK\", row_number().over(w))\n",
    "    \n",
    "    job_df = (\n",
    "        silver_principals\n",
    "        .select(col(\"CATEGORY\").alias(\"JOB_CATEGORY\"))\n",
    "        .filter(col(\"JOB_CATEGORY\").isNotNull() & (col(\"JOB_CATEGORY\") != \"unknown\"))\n",
    "        .dropDuplicates([\"JOB_CATEGORY\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"JOB_CATEGORY\")\n",
    "    job_df = job_df.withColumn(\"JOB_SK\", row_number().over(w))\n",
    "    \n",
    "    fact_df = (\n",
    "        silver_principals\n",
    "        .join(title_df, silver_principals[\"TCONST\"] == title_df[\"TCONST\"], \"inner\")\n",
    "        .join(person_df, silver_principals[\"NCONST\"] == person_df[\"NCONST\"], \"inner\")\n",
    "        .join(job_df, silver_principals[\"CATEGORY\"] == job_df[\"JOB_CATEGORY\"], \"inner\")\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(silver_principals[\"TCONST\"], silver_principals[\"NCONST\"], silver_principals[\"ORDERING\"])\n",
    "    fact_df = fact_df.withColumn(\"PARTICIPATION_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = fact_df.select(\n",
    "        col(\"PARTICIPATION_SK\").cast(\"int\"),\n",
    "        col(\"JOB_SK\").cast(\"int\"),\n",
    "        col(\"TITLE_BASICS_SK\").cast(\"int\"),\n",
    "        col(\"PERSON_SK\").cast(\"int\"),\n",
    "        silver_principals[\"ORDERING\"].cast(\"int\").alias(\"ORDERING\"),  # ‚Üê ADDED\n",
    "        lit(\"PRATHUSH\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"FACT_TITLE_PARTICIPATION\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# =========================================================================\n",
    "# FACT_TITLE_STATS\n",
    "# =========================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"snowflake_fact_title_stats\",\n",
    "    comment=\"Fact table for title statistics in Snowflake\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"type\": \"fact\",\n",
    "        \"target\": \"snowflake\"\n",
    "    }\n",
    ")\n",
    "def fact_title_stats():\n",
    "    silver_ratings = spark.read.table(\"imdb_final_project.silver.silver_title_ratings\")\n",
    "    silver_basics = spark.read.table(\"imdb_final_project.silver.silver_title_basics\")\n",
    "    silver_episode = spark.read.table(\"imdb_final_project.silver.silver_title_episode\")\n",
    "    \n",
    "    title_df = (\n",
    "        silver_basics\n",
    "        .select(\"TCONST\", \"RUNTIME_MINUTES\")\n",
    "        .filter(col(\"TCONST\").isNotNull())\n",
    "        .dropDuplicates([\"TCONST\"])\n",
    "    )\n",
    "    w = Window.orderBy(\"TCONST\")\n",
    "    title_df = title_df.withColumn(\"TITLE_BASICS_SK\", row_number().over(w))\n",
    "    \n",
    "    episode_agg = (\n",
    "        silver_episode\n",
    "        .groupBy(\"PARENTTCONST\", \"SEASON_NUMBER\")\n",
    "        .agg(count(\"TCONST\").alias(\"NO_OF_EPISODES\"))\n",
    "    )\n",
    "    \n",
    "    fact_df = (\n",
    "        silver_ratings\n",
    "        .join(title_df, silver_ratings[\"TCONST\"] == title_df[\"TCONST\"], \"inner\")\n",
    "        .join(episode_agg, silver_ratings[\"TCONST\"] == episode_agg[\"PARENTTCONST\"], \"left\")\n",
    "    )\n",
    "    \n",
    "    w = Window.orderBy(silver_ratings[\"TCONST\"], \"SEASON_NUMBER\")\n",
    "    fact_df = fact_df.withColumn(\"TITLE_STATS_SK\", row_number().over(w))\n",
    "    \n",
    "    final_df = fact_df.select(\n",
    "        col(\"TITLE_STATS_SK\").cast(\"int\"),\n",
    "        col(\"TITLE_BASICS_SK\").cast(\"int\"),\n",
    "        col(\"AVERAGE_RATING\").cast(\"decimal(3,1)\"),\n",
    "        col(\"RATING_CATEGORY\"),\n",
    "        col(\"NUM_VOTES\").cast(\"int\"),\n",
    "        col(\"RUNTIME_MINUTES\").cast(\"int\"),\n",
    "        coalesce(col(\"SEASON_NUMBER\"), lit(-1)).cast(\"int\").alias(\"SEASON_NUMBER\"),\n",
    "        coalesce(col(\"NO_OF_EPISODES\"), lit(-1)).cast(\"int\").alias(\"NO_OF_EPISODES\"),\n",
    "        lit(\"NIKHIL\").alias(\"DI_JOB_ID\"),\n",
    "        current_date().alias(\"DI_LOAD_DATE\")\n",
    "    )\n",
    "    \n",
    "    final_df.write \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**SNOWFLAKE_OPTIONS) \\\n",
    "        .option(\"dbtable\", \"FACT_TITLE_STATS\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    \n",
    "    return final_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IMDB_SILVER_2_GOLD(SNOWFLAKE)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}